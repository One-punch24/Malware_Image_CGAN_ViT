# Malware_Markov_Image_CGAN_ViT

We intend to implement a malware detection system using Vision Transformer (ViT) and second order Markov images obtained from opcode of the input binary files. 
* **Disassemble:** We obtain the binary code for both malware and benign software samples, and **disassemble** them in **batch process**. 
* **Stochastic Process and 2nd order Markov Matrix:** We consider the disassembled instructions as a stochastic process flow. We define every two adjacent opcodes as a state, and the transition between the two states is actually associated with four adjacent opcodes. More explicitly, a transition can be expressed as: (opcode[i], opcode[i+1])->(opcode[i+2], opcode[i+3]). The Markov matrix of this stochastic process is defined as the **2nd order Markov matrix**, since every state is two opcodes.
* **Opcode Parsing:** We construct a **parser** to extract the most frequently used opcodes and the most frequently appeared states (224 in total, to match with the neural network) in the disassembled files, filtering out all the pseudo-instrucions, registers and data. To construct the image inputs for our neural network, we used the IEEE 754 protocol to map the floating point elements in the matrix to RGB color in the corresponding pixel.
* **Model Trainning:** At last, we train the neural network model. After 30 epochs, the method can have
  * Validation Accuracy:  89.00983146067416%
  * Validation Accuracy For Larger Inputs (1500 non-zero pixels out of 150528 pixels): 92.48417721518987%
  * True Positive Rate: 87.53213367609255%
  * False Positive Rate: 12.467866323907455%
  * True Negative Rate: 90.75369075369075%
  * False Positive Rate: 9.246309246309246%

We Thank [ViT-pytorch](https://github.com/jeonsworld/ViT-pytorch). We are able to utilize the concise code while we add clear annotations for the implementation of ViT, especially focusing on the vicissitude of structure dimension.

## Preparation

### 1. Download Pre-trained model

* [Available models](https://console.cloud.google.com/storage/vit_models/): ViT-B_16(**85.8M**), R50+ViT-B_16(**97.96M**), ViT-B_32(**87.5M**), ViT-L_16(**303.4M**), ViT-L_32(**305.5M**), ViT-H_14(**630.8M**)
  * imagenet21k pre-train models
    * ViT-B_16, ViT-B_32, ViT-L_16, ViT-L_32, ViT-H_14

We simply use ViT-B_16.

### 2. Download Malevis Dataset

+ [MaleVis Dataset](https://web.cs.hacettepe.edu.tr/~selman/malevis/)

## Run

### 1 Train

```
python train.py --test False --dataset_dir xxxxx 
```

### 2 Test

```
python train.py --test True --dataset_dir xxxxx 
```

## Reference

[ViT-pytorch](https://github.com/jeonsworld/ViT-pytorch)

## Citation

```bibtex
@article{Markov,
  author = {zhongMou-lilSister, One-punch24},
  title = {Using Second Order Markov Matrix Obtained From Opcode Sequence For Malware Detection},
  year = {2021},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/One-punch24/Malware_Markov_Image_CGAN-ViT}},
}
```

