import torch
from torchvision import transforms,datasets
from torch.utils.data import DataLoader, RandomSampler, DistributedSampler, SequentialSampler

DATASET_TRAIN_PATH='D:\REPO\dataset\malevis_train_val_224x224\\train'
DATASET_VAL_PATH='D:\REPO\dataset\malevis_train_val_224x224\\val'

def get_loader(args,):

    transform_train = transforms.Compose([
        transforms.RandomResizedCrop((args.img_size, args.img_size), scale=(0.05, 1.0)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
    ])
    transform_test = transforms.Compose([
        transforms.Resize((args.img_size, args.img_size)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
    ])


    Mal_trainset=datasets.ImageFolder(root=DATASET_TRAIN_PATH,
        transform=transform_train)

    Mal_testset=datasets.ImageFolder(root=DATASET_TRAIN_PATH,
        transform=transform_train)

    train_sampler = RandomSampler(Mal_trainset)
    test_sampler = SequentialSampler(Mal_testset)
    train_loader = DataLoader(Mal_trainset,
                              sampler=train_sampler,
                              batch_size=args.train_batch_size,
                              num_workers=1,
                              pin_memory=True)
    test_loader = DataLoader(Mal_testset,
                             sampler=test_sampler,
                             batch_size=args.eval_batch_size,
                             num_workers=1,
                             pin_memory=True) 
    return train_loader,test_loader
import tqdm
if __name__=='__main__':
    train_dataset=datasets.ImageFolder(root=DATASET_TRAIN_PATH)
    train_loader = DataLoader(train_dataset,
                              batch_size=64,
                              num_workers=1,
                              pin_memory=True)
    print(len(train_loader))
    print(train_dataset.class_to_idx)
    tqdm(train_loader)